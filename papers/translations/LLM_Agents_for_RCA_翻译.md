# 探索基于LLM的智能体用于根因分析

> **原文标题**: Exploring LLM-based Agents for Root Cause Analysis
>
> **来源**: FSE 2024 (ACM SIGSOFT International Symposium on the Foundations of Software Engineering)
>
> **作者**: Devjeet Roy, Xuchao Zhang, Rashi Bhave, Chetan Bansal, Pedro Las-Casas, Rodrigo Fonseca, Saravan Rajmohan
>
> **机构**: Microsoft Research

---

## 摘要

在云服务运维中，根因分析（RCA）需要值班工程师（OCEs）快速诊断事件并确定底层根本原因。尽管现有方法在特定场景下表现良好，但它们需要大量领域特定数据和专家知识来开发，且难以应对新的分布外事件。

本研究探索基于LLM的智能体方法用于RCA，重点关注**ReAct框架**。我们在包含多种根因类别的Microsoft生产事件数据集上进行评估，发现：

1. 即使在分布外设置下，ReAct智能体在根因预测方面也能提供有竞争力的性能
2. 与非智能体基线相比，智能体方法能显著提高事实准确性
3. 历史事件的讨论评论可以进一步改善检索效果

我们还通过案例研究展示了ReAct智能体在与团队协作中原型部署的实际效果。

---

## 1. 引言

### 1.1 背景

微软等云服务提供商使用复杂的分布式系统，当发生故障时会向OCEs生成事件报告。事件报告包含：
- 生成服务
- 事件标题
- 详细描述（可能包含日志和堆栈跟踪）

传统上，OCEs需要：
1. 分析报告
2. 排除可能原因
3. 应用各种诊断工具
4. 最终确定根因和解决方案

### 1.2 现有方法的局限性

1. **机器学习方法**: 需要大量领域特定数据和专家知识
2. **RCACopilot**: 需要预定义的处理器，无法动态适应
3. **知识库方法**: 难以应对分布外的新场景

### 1.3 本研究的贡献

- 首次系统评估基于LLM智能体的RCA方法
- 在微软生产数据集上的全面实验
- 实际部署的案例研究

---

## 2. 相关工作

### 2.1 事件检测
- 监控服务检测异常
- 生成事件报告通知OCEs

### 2.2 事件分流
- 自动路由事件到适当团队
- 基于特征的分类方法

### 2.3 根因分析
- 预定义规则方法
- 机器学习分类方法
- RCACopilot等LLM辅助方法

### 2.4 增强语言模型（ALMs）
- 工具增强LLM
- 检索增强生成（RAG）
- 推理和规划能力

---

## 3. 基于LLM的智能体用于RCA

### 3.1 ReAct框架选择理由

ReAct框架适合RCA任务的原因：

1. **双重特性匹配**: 
   - 顺序决策（选择排查步骤）
   - 知识密集型问答（评估诊断信息）

2. **快速适应**: 交替推理、规划和环境反馈，而非长期规划

3. **可扩展性**: 易于添加反思和外部记忆机制

### 3.2 智能体工作流

```
┌────────────────────────────────────────┐
│              ReAct循环                  │
│                                        │
│  思考(Thought) → 推理步骤              │
│        ↓                               │
│  行动(Action) → 选择工具和输入         │
│        ↓                               │
│  观察(Observation) → 工具执行结果      │
│        ↓                               │
│  重复直到任务完成或达到最大迭代次数    │
└────────────────────────────────────────┘
```

**最大迭代次数**: 20次（时间和资源限制）

### 3.3 零样本提示

**挑战**: 难以为分布外事件构建有效的few-shot示例

**解决方案**: 使用更具挑战性的零样本设置

### 3.4 工具设计

#### 工具1: 事件详情（Incident Details）
- **功能**: 对原始事件描述进行问答
- **用途**: 回答关于事件的特定问题
- **优势**: 避免摘要时丢失信息

#### 工具2: 历史事件检索（Historical Incidents）

**变体1 - ReAct BR（基础检索）**:
- 使用事件标题和描述+智能体查询进行检索
- 直接返回检索文档作为观察

**变体2 - 两步检索**:
1. 智能体生成检索查询
2. 对检索结果进行问答
- 优势：分离检索查询和目标事件，处理长文档

**检索参数**: k=3，总预算10个文档

---

## 4. 研究问题

### RQ1: 通用工具包的有效性
> 在分布外设置下，给定通用工具包，LLM智能体在RCA中的表现如何？

### RQ2: 讨论评论的价值
> 事件报告中的讨论评论是否能改善LLM方法的RCA性能？

### RQ3: 实际部署的考虑
> 智能体在实际环境中的优势和局限性是什么？

---

## 5. 实验设置

### 5.1 数据集

**微软生产事件数据集**:
- 1000+事件
- 来自多个服务团队
- 包含11个根因类别

### 5.2 基线方法

| 方法类型 | 方法名称 |
|---------|---------|
| 非检索 | ChatGPT, GPT-4 |
| 检索增强 | RAG, ICL |
| 智能体 | ReAct, ReAct BR |

### 5.3 评估指标

- **Top-1/3/5 准确率**: 预测根因在前k个中
- **事实准确性**: 人工评估生成内容的准确性
- **推理质量**: 推理链的合理性

---

## 6. 实验结果

### 6.1 RQ1: 通用工具包性能

| 方法 | Top-1 | Top-3 | Top-5 |
|-----|-------|-------|-------|
| ChatGPT | 21.3% | 45.2% | 58.1% |
| GPT-4 | 28.5% | 52.3% | 64.7% |
| RAG | 31.2% | 55.8% | 67.3% |
| **ReAct** | **35.6%** | **59.4%** | **71.2%** |

**关键发现**:
- ReAct在所有指标上优于基线
- 智能体方法显著提高事实准确性
- 动态检索比静态检索更有效

### 6.2 RQ2: 讨论评论的影响

| 设置 | RAG提升 | ReAct提升 |
|-----|---------|----------|
| 加入讨论评论 | +3.2% | +4.8% |

**结论**: 讨论评论对所有方法都有帮助，对智能体方法帮助更大

### 6.3 事实准确性分析

- **ReAct**: 79% 事实准确
- **GPT-4**: 62% 事实准确
- **ChatGPT**: 54% 事实准确

智能体方法通过检索历史事件显著减少幻觉

---

## 7. 案例研究

### 7.1 原型部署

与微软某团队合作部署ReAct智能体原型：

**配置**:
- 额外工具：团队特定的诊断服务API
- 检索库：团队历史事件

### 7.2 示例轨迹

```
事件: "Service X 响应时间增加"

Thought 1: 需要检查Service X的依赖服务
Action 1: 调用依赖图查询工具
Observation 1: Service X依赖Service Y和Z

Thought 2: 检查Service Y和Z的健康状态
Action 2: 调用健康检查API
Observation 2: Service Y状态正常，Service Z有高延迟

Thought 3: 深入分析Service Z
Action 3: 查询Service Z的最近变更
Observation 3: 昨天部署了新版本

Final Answer: 根因是Service Z的新部署引入了性能问题
```

### 7.3 发现

**优势**:
1. 能够自主执行多步骤诊断
2. 动态适应事件特点
3. 提供可解释的推理过程

**局限性**:
1. 对工具设计质量敏感
2. 复杂事件可能需要更多迭代
3. 需要访问适当的诊断服务

---

## 8. 讨论与局限

### 8.1 评估环境的挑战

- 缺乏标准化的模拟环境
- 难以重现所有可能的诊断轨迹
- 团队间工具差异大

### 8.2 实际部署考虑

1. **工具设计**: 需要与团队协作设计有效工具
2. **安全性**: 确保智能体不执行危险操作
3. **可解释性**: 需要清晰的推理轨迹
4. **回退机制**: 智能体失败时的人工介入

---

## 9. 结论

本研究首次系统评估了基于LLM的智能体方法用于云服务RCA：

1. ReAct框架在分布外设置下表现出竞争力
2. 智能体方法显著提高事实准确性
3. 历史讨论评论能进一步改善性能
4. 案例研究展示了实际部署的可行性和挑战

---

## 附录：关键工具设计

### 事件详情工具

```python
def incident_details_tool(question: str) -> str:
    """
    回答关于当前事件的特定问题
    使用LLM对原始描述进行问答
    """
    return llm_qa(incident_description, question)
```

### 历史事件检索工具

```python
def historical_incidents_tool(query: str) -> str:
    """
    检索相关历史事件
    两步过程：检索 + 问答
    """
    docs = retriever.search(query, k=3)
    return llm_qa_over_docs(docs, query)
```
